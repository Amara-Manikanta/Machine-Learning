{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green; text-align:center;display:block;\">Decision Tree</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. \n",
    "- It works by splitting the data into different subsets based on the most significant features (decisions), forming a tree structure.\n",
    "-  At each node, the algorithm asks a yes/no question, and branches are formed based on the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of a Decision Tree\n",
    "1. <b>Root Node:</b> Represents the entire dataset and the initial decision to be made.\n",
    "2. <b>Internal Nodes:</b> Represent decisions or tests on attributes. Each internal node has one or more branches.\n",
    "3. <b>Branches:</b> Represent the outcome of a decision or test, leading to another node.\n",
    "4. <b>Leaf Nodes:</b> Represent the final decision or prediction. No further splits occur at these nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Splitting in Decision Trees\n",
    "\n",
    "When constructing decision trees, different metrics are used to determine the best way to split the dataset at each node. Here are the most common splitting criteria:\n",
    "\n",
    "### 1. **Gini Impurity**\n",
    "   - **Used in:** Classification tasks (e.g., CART - Classification and Regression Trees)\n",
    "   - **Definition:** Measures the likelihood of incorrectly classifying a randomly chosen element if it was randomly labeled according to the distribution of labels in the subset.\n",
    "   - **Formula:**\n",
    "     \\[\n",
    "     Gini = 1 - \\sum_{i=1}^{n} p_i^2\n",
    "     \\]\n",
    "     Where \\( p_i \\) is the proportion of samples of class \\( i \\) in the subset.\n",
    "   - **Goal:** Minimize Gini impurity at each split.\n",
    "   - **Range:** 0 (pure) to 0.5 (impure).\n",
    "\n",
    "### 2. **Entropy (Information Gain)**\n",
    "   - **Used in:** Classification tasks (e.g., ID3, C4.5)\n",
    "   - **Definition:** A measure of the randomness or disorder in the data. Entropy is used to calculate **information gain**, which is the reduction in entropy after a split.\n",
    "   - **Formula:**\n",
    "     \\[\n",
    "     Entropy = -\\sum_{i=1}^{n} p_i \\log_2(p_i)\n",
    "     \\]\n",
    "     Where \\( p_i \\) is the proportion of samples of class \\( i \\) in the subset.\n",
    "   - **Information Gain:**\n",
    "     \\[\n",
    "     Information\\ Gain = Entropy(parent) - \\sum \\left(\\frac{n_k}{n}\\right) Entropy(k)\n",
    "     \\]\n",
    "   - **Goal:** Maximize information gain (reduce entropy).\n",
    "   - **Range:** 0 (pure) to log(n) (impure).\n",
    "\n",
    "### 3. **Variance Reduction (Mean Squared Error)**\n",
    "   - **Used in:** Regression tasks\n",
    "   - **Definition:** The variance reduction metric is used to minimize the variance of the target variable in each split.\n",
    "   - **Formula:**\n",
    "     \\[\n",
    "     Variance = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\mu)^2\n",
    "     \\]\n",
    "     Where \\( y_i \\) is the actual target value, and \\( \\mu \\) is the mean of the target values.\n",
    "   - **Goal:** Minimize the variance of the target values within the child nodes.\n",
    "\n",
    "### 4. **Mean Absolute Error (MAE)**\n",
    "   - **Used in:** Regression tasks\n",
    "   - **Definition:** MAE measures the average of the absolute differences between predicted values and actual values.\n",
    "   - **Formula:**\n",
    "     \\[\n",
    "     MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}|\n",
    "     \\]\n",
    "     Where \\( y_i \\) is the actual value and \\( \\hat{y_i} \\) is the predicted value.\n",
    "   - **Goal:** Minimize the absolute difference between predictions and actual values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
