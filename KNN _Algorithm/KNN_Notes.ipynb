{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts of KNN**\n",
    "\n",
    "- **Instance-Based Learning**: \n",
    "    - KNN is a type of instance-based learning where the algorithm does not explicitly learn a model.\n",
    "    - Instead, it memorizes the training data and makes predictions by comparing new data points to the stored instances.\n",
    "    \n",
    "- **Distance Metric**: \n",
    "    - KNN relies on a distance metric to find the nearest neighbors. Common distance metrics include:\n",
    "        - **Euclidean Distance**: \\( \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2} \\)\n",
    "        - **Manhattan Distance**: \\( \\sum_{i=1}^{n} |x_i - y_i| \\)\n",
    "        - **Minkowski Distance**: A generalized form of Euclidean and Manhattan distances.\n",
    "    \n",
    "- **Parameter K**: \n",
    "    - The parameter \\( k \\) represents the number of nearest neighbors to consider when making a prediction. \n",
    "    - The choice of \\( k \\) can significantly affect the performance of the algorithm. \n",
    "    - A smaller \\( k \\) can be noisy and susceptible to outliers, while a larger \\( k \\) provides a smoother decision boundary.\n",
    "\n",
    "\n",
    "    \n",
    "- **Regression**:\n",
    "    - **Training Phase**: The algorithm stores the training data.\n",
    "    - **Prediction Phase**:\n",
    "        - For a new data point, calculate the distance between this point and all the points in the training set.\n",
    "        - Select the \\( k \\) training points that are closest to the new data point.\n",
    "        - Predict the value as the average of the values of these \\( k \\) neighbors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How KNN Works**\n",
    "\n",
    "- **Classification**:\n",
    "    - **Training Phase**: The algorithm stores the training data.\n",
    "    - **Prediction Phase**:\n",
    "        - For a new data point, calculate the distance between this point and all the points in the training set.\n",
    "        - Select the \\( k \\) training points that are closest to the new data point.\n",
    "        - Assign the most common class among these \\( k \\) neighbors to the new data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of KNN\n",
    "\n",
    "1. **Accuracy**\n",
    "    - Measures the proportion of correctly classified instances out of the total instances.\n",
    "    - Suitable for balanced datasets.\n",
    "    - Formula: \n",
    "      \\[\n",
    "      \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "      \\]\n",
    "\n",
    "2. **Precision**\n",
    "    - Measures the proportion of true positive instances out of the total predicted positive instances.\n",
    "    - Important for scenarios where false positives are costly.\n",
    "    - Formula:\n",
    "      \\[\n",
    "      \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "      \\]\n",
    "\n",
    "3. **Recall (Sensitivity)**\n",
    "    - Measures the proportion of true positive instances out of the total actual positive instances.\n",
    "    - Important for scenarios where false negatives are costly.\n",
    "    - Formula:\n",
    "      \\[\n",
    "      \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "      \\]\n",
    "\n",
    "4. **F1 Score**\n",
    "    - Harmonic mean of precision and recall.\n",
    "    - Balances precision and recall, useful when the dataset is imbalanced.\n",
    "    - Formula:\n",
    "      \\[\n",
    "      \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "      \\]\n",
    "\n",
    "5. **Confusion Matrix**\n",
    "    - A table used to describe the performance of a classification model.\n",
    "    - Contains the counts of true positives, true negatives, false positives, and false negatives.\n",
    "    - Example:\n",
    "\n",
    "      |                | Predicted Positive | Predicted Negative |\n",
    "      |----------------|--------------------|--------------------|\n",
    "      | **Actual Positive** | True Positive (TP)    | False Negative (FN)   |\n",
    "      | **Actual Negative** | False Positive (FP)   | True Negative (TN)    |\n",
    "\n",
    "6. **ROC Curve (Receiver Operating Characteristic Curve)**\n",
    "    - A plot of the true positive rate (recall) against the false positive rate at various threshold settings.\n",
    "    - Helps visualize the performance of a classifier.\n",
    "\n",
    "7. **AUC (Area Under the Curve)**\n",
    "    - Represents the area under the ROC curve.\n",
    "    - Values range from 0 to 1, where a value closer to 1 indicates better performance.\n",
    "\n",
    "8. **Cross-Validation**\n",
    "    - Technique to evaluate the performance of a model by partitioning the data into subsets.\n",
    "    - Common methods include k-fold cross-validation and stratified k-fold cross-validation.\n",
    "    - Helps in assessing the model's generalizability to unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
